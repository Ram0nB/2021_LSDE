{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64e9b1bb-5a0a-449b-9559-f44071def96d",
   "metadata": {},
   "source": [
    "Uncompress and split laz/las in multiple las files with specified target size. Assumes points to be uniform distributed over space to determine how many rows/columns the original file will be split into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7836f186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import laspy\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0e24241-e2ba-4c04-88a7-d8239a997bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit()\n",
    "def find_rowcol(value, intervals):\n",
    "    \"\"\"\n",
    "    helper function for lasz_to_smaller_las\n",
    "    \"\"\"\n",
    "    for rowcol, intval in enumerate(intervals):\n",
    "        if value <= intval:\n",
    "            return rowcol\n",
    "    print(\"NO ROW OR COLUMN FOUND??\")\n",
    "    return None\n",
    "\n",
    "@nb.njit(parallel=True)\n",
    "def get_row_col(xpoints, ypoints, row_x_intervals, col_y_intervals):\n",
    "    \"\"\"\n",
    "    helper function for lasz_to_smaller_las\n",
    "    \"\"\"\n",
    "    n_points = len(xpoints)\n",
    "    xpoints_rows = np.zeros(n_points, dtype=np.int64)\n",
    "    ypoints_cols = np.zeros(n_points, dtype=np.int64)\n",
    "    for i in nb.prange(n_points):\n",
    "        xpoints_rows[i] = find_rowcol(xpoints[i], row_x_intervals)\n",
    "        ypoints_cols[i] = find_rowcol(ypoints[i], col_y_intervals)\n",
    "    \n",
    "    return xpoints_rows, ypoints_cols\n",
    "\n",
    "@nb.njit(parallel=True)\n",
    "def points_mask_from_row_col(xpoints_rows, ypoints_cols, row, col):\n",
    "    \"\"\"\n",
    "    helper function for lasz_to_smaller_las\n",
    "    \"\"\"\n",
    "    n_points = len(xpoints_rows)\n",
    "    mask = np.zeros(n_points, dtype=np.bool_)\n",
    "    for i in nb.prange(n_points):\n",
    "        if xpoints_rows[i] == row and ypoints_cols[i] == col:\n",
    "            mask[i] = True\n",
    "    return mask\n",
    "\n",
    "def lasz_to_smaller_las(fname_in, fname_out, max_out_MB, chunksize):\n",
    "    \"\"\"\n",
    "    - max target size in megabytes\n",
    "    - assumes points to be uniformly distributed over x and y\n",
    "    - creates new las files with _row_col appended to fname_out\n",
    "    \"\"\"\n",
    "    # determine the amount of rows and columns to split the original file in\n",
    "    in_MB = os.path.getsize(fname_in)/1000000\n",
    "    n_col = 1\n",
    "    n_row = 1\n",
    "    counter = 0\n",
    "    while in_MB/(n_col*n_row) > max_out_MB:\n",
    "        counter += 1\n",
    "        if counter % 2 == 1:\n",
    "            n_row += 1\n",
    "        else:\n",
    "            n_col += 1\n",
    "    print(\"file in MB / (columns * rows) = files out MB\")\n",
    "    print(f\"{in_MB} / ({n_col}*{n_row}) = {in_MB/(n_col*n_row)}\")\n",
    "    \n",
    "    with laspy.open(fname_in) as src:\n",
    "        # get x y min max values of src\n",
    "        x_min = src.header.x_min\n",
    "        x_max = src.header.x_max\n",
    "        y_min = src.header.y_min\n",
    "        y_max = src.header.y_max\n",
    "    \n",
    "        # init files to write to\n",
    "        for row in range(n_row):\n",
    "            for col in range(n_col):\n",
    "                name = fname_out.split(\".\")[-2]+f\"_{row}_{col}.las\"\n",
    "                dst_file = laspy.create(point_format=src.header.point_format, file_version=src.header.version)\n",
    "                dst_file.write(name)\n",
    "\n",
    "    # construct intervals\n",
    "    x_range = x_max - x_min\n",
    "    y_range = y_max - y_min\n",
    "    x_step = x_range / n_row\n",
    "    y_step = y_range / n_col\n",
    "    row_x_intervals = [] # upper values for the rows\n",
    "    col_y_intervals = [] # upper values for the cols\n",
    "    for i in range(n_row):\n",
    "        row_x_intervals.append((i+1)*x_step + x_min)\n",
    "    for i in range(n_col):\n",
    "        col_y_intervals.append((i+1)*y_step + y_min)\n",
    "    row_x_intervals = np.array(row_x_intervals, dtype=np.float64)\n",
    "    col_y_intervals = np.array(col_y_intervals, dtype=np.float64)\n",
    "\n",
    "    # open src file and iterate over points per chunk\n",
    "    with laspy.open(fname_in) as src:\n",
    "        src_point_count = src.header.point_count\n",
    "        counter = 0\n",
    "        for points in src.chunk_iterator(chunksize):\n",
    "            \n",
    "            # get points x and y values\n",
    "            xpoints = np.array(points.x, dtype=np.float64)\n",
    "            ypoints = np.array(points.y, dtype=np.float64)\n",
    "        \n",
    "            # determine which row and column the points are in\n",
    "            xpoints_rows, ypoints_cols = get_row_col(xpoints, ypoints, row_x_intervals, col_y_intervals)\n",
    "        \n",
    "            # write points to corresponding row/column file\n",
    "            for row in range(n_row):\n",
    "                for col in range(n_col):\n",
    "                    points_mask = points_mask_from_row_col(xpoints_rows, ypoints_cols, row, col)\n",
    "                    points_towrite = points[points_mask]\n",
    "                    if len(points_towrite) != 0:\n",
    "                        name = fname_out.split(\".\")[-2]+f\"_{row}_{col}.las\"\n",
    "                        with laspy.open(name, mode='a') as dst:\n",
    "                            dst.append_points(points_towrite)\n",
    "                    \n",
    "            counter += 1\n",
    "            if (counter*chunksize)/src_point_count < 1:\n",
    "                print(f\"{round((counter*chunksize)/src_point_count, 2)} done\")\n",
    "            else:\n",
    "                print(\"ENTIRELY DONE\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3de69aa-26ee-4775-a197-f3495befaf29",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfb97631-90d2-49c4-908d-8a900058d61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file in MB / (columns * rows) = files out MB\n",
      "1411.435569 / (2*3) = 235.2392615\n",
      "0.2 done\n",
      "0.4 done\n",
      "0.6 done\n",
      "0.79 done\n",
      "0.99 done\n",
      "ENTIRELY DONE\n"
     ]
    }
   ],
   "source": [
    "fname_in = \"C_64EZ2_pred.las\"\n",
    "fname_out = \"C_64EZ2_pred_smol.las\"\n",
    "max_out_MB = 250\n",
    "chunksize = 10_000_000\n",
    "\n",
    "lasz_to_smaller_las(fname_in, fname_out, max_out_MB, chunksize)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
